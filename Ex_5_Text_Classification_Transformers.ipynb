{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d2eb666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"./news-headlines-dataset-for-sarcasm-detection\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "import opendatasets as od\n",
    "od.download(\"https://www.kaggle.com/datasets/rmisra/news-headlines-dataset-for-sarcasm-detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "051de1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from torch.optim import Adam\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"Available Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "affbc7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26708, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  former versace store clerk sues over secret 'b...             0\n",
       "1  the 'roseanne' revival catches up to our thorn...             0\n",
       "2  mom starting to fear son's web series closest ...             1\n",
       "3  boehner just wants wife to listen, not come up...             1\n",
       "4  j.k. rowling wishes snape happy birthday in th...             0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_json(\"news-headlines-dataset-for-sarcasm-detection/Sarcasm_Headlines_Dataset.json\", lines = True)\n",
    "data_df.dropna(inplace=True)\n",
    "data_df.drop_duplicates(inplace=True)\n",
    "data_df.drop([\"article_link\"], inplace=True, axis=1)\n",
    "print(data_df.shape)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b25d2b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size: 18695 Which is :  70.0 %\n",
      "val Size: 4006 Which is :  15.0 %\n",
      "test Size: 4007 Which is :  15.0 %\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(np.array(data_df[\"headline\"]), np.array(data_df[\"is_sarcastic\"]), train_size=0.7)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_test, Y_test, train_size=0.5)\n",
    "\n",
    "print(\"Training Size:\",X_train.shape[0], \"Which is : \", round(X_train.shape[0] / data_df[\"headline\"].__len__() * 100, 2), \"%\")\n",
    "print(\"val Size:\",X_val.shape[0], \"Which is : \", round(X_val.shape[0] / data_df[\"headline\"].__len__() * 100, 2), \"%\")\n",
    "print(\"test Size:\",X_test.shape[0], \"Which is : \", round(X_test.shape[0] / data_df[\"headline\"].__len__() * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ee4b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "bert_model = AutoModel.from_pretrained(\"google-bert/bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0de6ba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = [tokenizer(x,\n",
    "                            max_length=100,\n",
    "                            truncation=True,\n",
    "                            padding=\"max_length\",\n",
    "                            return_tensors='pt').to(device)\n",
    "                            for x in X\n",
    "                            ]\n",
    "        self.Y = torch.tensor(Y, dtype=torch.float32).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "    \n",
    "train_dataset = dataset(X_train, Y_train)\n",
    "val_dataset = dataset(X_val, Y_val)\n",
    "test_dataset = dataset(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08d08236",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "Lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f509c30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c452786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.bert = bert\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.linear1 = nn.Linear(768, 384)\n",
    "        self.linear2 = nn.Linear(384, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_ids, attention_masks):\n",
    "        x = self.bert(input_ids, attention_masks, return_dict=False)[0][:,0]\n",
    "        x = self.linear1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "20c2734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in bert_model.parameters():\n",
    "    param.requires_grad = False\n",
    "model = Model(bert_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "445f1506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.25, inplace=False)\n",
      "  (linear1): Linear(in_features=768, out_features=384, bias=True)\n",
      "  (linear2): Linear(in_features=384, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6c0abee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteration = nn.BCELoss()\n",
    "optimizer = Adam(model.parameters(), lr=Lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a5bf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Train: L 0.0003 ● A 87.17% | Val: L 0.0003 ● A 86.12%: 100%|██████████| 10/10 [10:56<00:00, 65.62s/epoch]\n"
     ]
    }
   ],
   "source": [
    "total_loss_train_plot = []\n",
    "total_loss_val_plot = []\n",
    "total_acc_train_plot = []\n",
    "total_acc_val_plot = []\n",
    "\n",
    "pbar = tqdm(range(epochs), desc='Training', unit='epoch', leave=True)\n",
    "\n",
    "for epoch in pbar:\n",
    "    total_loss_train = 0\n",
    "    total_acc_train = 0\n",
    "    total_loss_val = 0\n",
    "    total_acc_val = 0\n",
    "\n",
    "    for index, data in enumerate(train_dataloader):\n",
    "\n",
    "        inputs, labels = data\n",
    "        inputs.to(device)\n",
    "        labels.to(device)\n",
    "\n",
    "        outputs = model(inputs[\"input_ids\"].squeeze(1), inputs[\"attention_mask\"].squeeze(1)).squeeze(1)\n",
    "        batch_loss = criteration(outputs, labels)\n",
    "\n",
    "        total_loss_train += batch_loss.item()\n",
    "\n",
    "        train_acc = (outputs.round() == labels).sum().item()\n",
    "        total_acc_train += train_acc\n",
    "\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for index, data  in enumerate(val_dataloader):\n",
    "\n",
    "            inputs, labels = data\n",
    "            inputs.to(device)\n",
    "            labels.to(device)\n",
    "\n",
    "            outputs = model(inputs[\"input_ids\"].squeeze(1), inputs[\"attention_mask\"].squeeze(1)).squeeze(1)\n",
    "            batch_loss = criteration(outputs, labels)\n",
    "\n",
    "            total_loss_val += batch_loss.item()\n",
    "\n",
    "            val_acc = (outputs.round() == labels).sum().item()\n",
    "            total_acc_val += val_acc\n",
    "\n",
    "    total_loss_train_plot.append(round(total_loss_train * batch_size/len(train_dataset), 4))\n",
    "    total_loss_val_plot.append(round(total_loss_val * batch_size/len(val_dataset), 4))\n",
    "    total_acc_train_plot.append(round(total_acc_train/len(train_dataset)*100, 4))\n",
    "    total_acc_val_plot.append(round(total_acc_val/len(val_dataset)*100, 4))\n",
    "\n",
    "    # 更新tqdm描述（关键修改点）\n",
    "    pbar.set_description(\n",
    "        f'Epoch {epoch+1}/{epochs} | '\n",
    "        f'Train: L {total_loss_train_plot[epoch]:.4f} ● A {total_acc_train_plot[epoch]:.2f}% | '\n",
    "        f'Val: L {total_loss_val_plot[epoch]:.4f} ● A {total_acc_val_plot[epoch]:.2f}%',\n",
    "        refresh=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e0da7a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3185\n",
      "Acc: 86.0744\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    total_loss_test = 0\n",
    "    total_acc_test = 0\n",
    "    for index, data  in enumerate(test_dataloader):\n",
    "\n",
    "        inputs, labels = data\n",
    "        inputs.to(device)\n",
    "        labels.to(device)\n",
    "\n",
    "        outputs = model(inputs[\"input_ids\"].squeeze(1), inputs[\"attention_mask\"].squeeze(1)).squeeze(1)\n",
    "        batch_loss = criteration(outputs, labels)\n",
    "\n",
    "        total_loss_test += batch_loss.item()\n",
    "\n",
    "        test_acc = (outputs.round() == labels).sum().item()\n",
    "        total_acc_test += test_acc\n",
    "\n",
    "    print(f\"Loss: {round(total_loss_test * batch_size/len(test_dataset), 4)}\")\n",
    "    print(f\"Acc: {round(total_acc_test/len(test_dataset)*100, 4)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
